{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":2298360,"sourceType":"datasetVersion","datasetId":1385643}],"dockerImageVersionId":30839,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true},"colab":{"provenance":[]}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## Importamos as bibliotecas","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport cv2\nimport os\nfrom PIL import Image\nimport tensorflow as tf\nfrom tensorflow.keras.utils import to_categorical\nfrom tensorflow.keras.applications.vgg16 import preprocess_input\nfrom sklearn.model_selection import train_test_split\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Dropout, Flatten\nfrom tensorflow.keras.applications import VGG16\nfrom tensorflow.keras.callbacks import LearningRateScheduler, ModelCheckpoint","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-14T13:11:43.679041Z","iopub.execute_input":"2025-02-14T13:11:43.679324Z","iopub.status.idle":"2025-02-14T13:11:56.171239Z","shell.execute_reply.started":"2025-02-14T13:11:43.679301Z","shell.execute_reply":"2025-02-14T13:11:56.170561Z"}},"outputs":[],"execution_count":1},{"cell_type":"markdown","source":"## Baixamos o dataset","metadata":{"execution":{"iopub.status.busy":"2025-02-13T18:20:38.956299Z","iopub.execute_input":"2025-02-13T18:20:38.956760Z","iopub.status.idle":"2025-02-13T18:20:38.962766Z","shell.execute_reply.started":"2025-02-13T18:20:38.956729Z","shell.execute_reply":"2025-02-13T18:20:38.961050Z"}}},{"cell_type":"code","source":"\n# Configuração para evitar logs desnecessários\ntf.get_logger().setLevel('ERROR')\n\n# Defina o caminho da pasta principal onde estão os dados\npasta = \"/kaggle/input/the-algae-cell-images/algae_data_11\"\n\n# Verificar se a pasta foi extraída corretamente\nif not os.path.exists(pasta):\n    print(\"Erro: O dataset não foi extraído corretamente.\")\nelse:\n    print(\"Dataset extraído com sucesso!\")\n\n# Inicialize os arrays para armazenar os dados e os rótulos\ndataset = []\nlabel = []\nSIZE = 224\n\n# Obtenha a lista de categorias (subpastas)\ncategorias = [d for d in os.listdir(pasta) if os.path.isdir(os.path.join(pasta, d))]\n\n# Iterar sobre cada categoria\nfor label_idx, categoria in enumerate(categorias):\n    subpasta = os.path.join(pasta, categoria)\n    imagens = [img for img in os.listdir(subpasta) if img.endswith('.jpg')]\n\n    for image_name in imagens:\n        img_path = os.path.join(subpasta, image_name)\n        img = cv2.imread(img_path)\n\n        if img is not None:\n            img = Image.fromarray(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n            img = img.resize((SIZE, SIZE))\n            dataset.append(np.array(img))\n            label.append(label_idx)\n\nprint(f\"Dataset criado com {len(dataset)} imagens e {len(label)} rótulos.\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-14T13:11:56.174890Z","iopub.execute_input":"2025-02-14T13:11:56.175097Z","iopub.status.idle":"2025-02-14T13:13:19.524241Z","shell.execute_reply.started":"2025-02-14T13:11:56.175079Z","shell.execute_reply":"2025-02-14T13:13:19.523512Z"}},"outputs":[{"name":"stdout","text":"Dataset extraído com sucesso!\nDataset criado com 6300 imagens e 6300 rótulos.\n","output_type":"stream"}],"execution_count":2},{"cell_type":"markdown","source":"## Processamos os dados","metadata":{}},{"cell_type":"code","source":"\n\n# Pré-processamento dos dados\ndef preprocess_data(X, Y):\n    X = X.astype('float32')\n    X_p = preprocess_input(X)\n    Y_p = to_categorical(Y, len(categorias))\n    return X_p, Y_p\n\n# Conversão para numpy arrays\ndataset = np.array(dataset)\nlabel = np.array(label)\n\n# Divisão dos dados\nX_train, X_temp, Y_train, Y_temp = train_test_split(dataset, label, \n                                                    test_size=0.4, \n                                                    random_state=42)\nX_val, X_test, Y_val, Y_test = train_test_split(X_temp, \n                                                Y_temp, \n                                                test_size=0.5, \n                                                random_state=42)\n\nX_train_p, Y_train_p = preprocess_data(X_train, Y_train)\nX_val_p, Y_val_p = preprocess_data(X_val, Y_val)\nX_test_p, Y_test_p = preprocess_data(X_test, Y_test)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-14T13:14:09.198959Z","iopub.execute_input":"2025-02-14T13:14:09.199260Z","iopub.status.idle":"2025-02-14T13:14:11.941114Z","shell.execute_reply.started":"2025-02-14T13:14:09.199242Z","shell.execute_reply":"2025-02-14T13:14:11.940171Z"}},"outputs":[],"execution_count":3},{"cell_type":"markdown","source":"## Definimos o modelo","metadata":{}},{"cell_type":"code","source":"\n# Construção do modelo\nbase_model = VGG16(include_top=False, \n                   weights='imagenet', \n                   pooling='avg', \n                   input_shape=(224, 224, 3))\n\n# Dicionário para armazenar os históricos de treinamento\nhistory_dict = {}\n\nmodel = Sequential([\n    base_model,\n    Flatten(),\n    Dense(512, activation='relu'),\n    Dropout(0.2),\n    Dense(256, activation='relu'),\n    Dropout(0.2),\n    Dense(len(categorias), activation='softmax')\n])\n\n# Callbacks\ndef decay(epoch):\n    \"\"\"Função para ajustar a taxa de aprendizado.\"\"\"\n    return 0.001 / (1 + 1 * 20)\n\n# Lista de callbacks\ncallbacks = [\n    LearningRateScheduler(decay, verbose=1),\n    ModelCheckpoint('/kaggle/working/phytoplankton.keras', \n                    save_best_only=True, \n                    monitor='val_loss', \n                    mode='min')\n]\n\n# Compilação do modelo\nmodel.compile(optimizer='adam', \n              loss='categorical_crossentropy', \n              metrics=['accuracy'])\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-14T13:14:22.359891Z","iopub.execute_input":"2025-02-14T13:14:22.360219Z","iopub.status.idle":"2025-02-14T13:14:25.168979Z","shell.execute_reply.started":"2025-02-14T13:14:22.360194Z","shell.execute_reply":"2025-02-14T13:14:25.168266Z"}},"outputs":[{"name":"stdout","text":"Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n\u001b[1m58889256/58889256\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n","output_type":"stream"}],"execution_count":4},{"cell_type":"markdown","source":"## Treinamos o modelo","metadata":{}},{"cell_type":"code","source":"\n# Treinamento\nfor batch_size in [16, 32, 64]:\n    history = model.fit(X_train_p, \n                        Y_train_p, \n                        batch_size=batch_size, \n                        validation_data=(X_val_p, Y_val_p), \n                        epochs=100, \n                        shuffle=True, \n                        callbacks=callbacks,\n                        verbose=1)\n\n# Armazena o histórico de treinamento no dicionário\nhistory_dict[batch_size] = history","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-14T13:14:42.369962Z","iopub.execute_input":"2025-02-14T13:14:42.370261Z","iopub.status.idle":"2025-02-14T19:34:30.135059Z","shell.execute_reply.started":"2025-02-14T13:14:42.370240Z","shell.execute_reply":"2025-02-14T19:34:30.134015Z"}},"outputs":[{"name":"stdout","text":"\nEpoch 1: LearningRateScheduler setting learning rate to 4.761904761904762e-05.\nEpoch 1/100\n\u001b[1m237/237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m122s\u001b[0m 402ms/step - accuracy: 0.6195 - loss: 1.6039 - val_accuracy: 0.7437 - val_loss: 0.8118 - learning_rate: 4.7619e-05\n\nEpoch 2: LearningRateScheduler setting learning rate to 4.761904761904762e-05.\nEpoch 2/100\n\u001b[1m237/237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m72s\u001b[0m 302ms/step - accuracy: 0.7771 - loss: 0.7161 - val_accuracy: 0.7905 - val_loss: 0.7353 - learning_rate: 4.7619e-05\n\nEpoch 3: LearningRateScheduler setting learning rate to 4.761904761904762e-05.\nEpoch 3/100\n\u001b[1m237/237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 310ms/step - accuracy: 0.8437 - loss: 0.4830 - val_accuracy: 0.8325 - val_loss: 0.6747 - learning_rate: 4.7619e-05\n\nEpoch 4: LearningRateScheduler setting learning rate to 4.761904761904762e-05.\nEpoch 4/100\n\u001b[1m237/237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 324ms/step - accuracy: 0.8795 - loss: 0.3922 - val_accuracy: 0.9024 - val_loss: 0.3500 - learning_rate: 4.7619e-05\n\nEpoch 5: LearningRateScheduler setting learning rate to 4.761904761904762e-05.\nEpoch 5/100\n\u001b[1m237/237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 329ms/step - accuracy: 0.9205 - loss: 0.2475 - val_accuracy: 0.8778 - val_loss: 0.4142 - learning_rate: 4.7619e-05\n\nEpoch 6: LearningRateScheduler setting learning rate to 4.761904761904762e-05.\nEpoch 6/100\n\u001b[1m237/237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 332ms/step - accuracy: 0.9358 - loss: 0.2162 - val_accuracy: 0.9167 - val_loss: 0.2966 - learning_rate: 4.7619e-05\n\nEpoch 7: LearningRateScheduler setting learning rate to 4.761904761904762e-05.\nEpoch 7/100\n\u001b[1m237/237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 332ms/step - accuracy: 0.9446 - loss: 0.1666 - val_accuracy: 0.9056 - val_loss: 0.3898 - learning_rate: 4.7619e-05\n\nEpoch 8: LearningRateScheduler setting learning rate to 4.761904761904762e-05.\nEpoch 8/100\n\u001b[1m237/237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 331ms/step - accuracy: 0.9538 - loss: 0.1625 - val_accuracy: 0.9222 - val_loss: 0.4173 - learning_rate: 4.7619e-05\n\nEpoch 9: LearningRateScheduler setting learning rate to 4.761904761904762e-05.\nEpoch 9/100\n\u001b[1m237/237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 331ms/step - accuracy: 0.9669 - loss: 0.1161 - val_accuracy: 0.8754 - val_loss: 0.5759 - learning_rate: 4.7619e-05\n\nEpoch 10: LearningRateScheduler setting learning rate to 4.761904761904762e-05.\nEpoch 10/100\n\u001b[1m237/237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 330ms/step - accuracy: 0.9581 - loss: 0.1538 - val_accuracy: 0.9095 - val_loss: 0.6573 - learning_rate: 4.7619e-05\n\nEpoch 11: LearningRateScheduler setting learning rate to 4.761904761904762e-05.\nEpoch 11/100\n\u001b[1m237/237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 332ms/step - accuracy: 0.9770 - loss: 0.0908 - val_accuracy: 0.9143 - val_loss: 0.3571 - learning_rate: 4.7619e-05\n\nEpoch 12: LearningRateScheduler setting learning rate to 4.761904761904762e-05.\nEpoch 12/100\n\u001b[1m237/237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 331ms/step - accuracy: 0.9808 - loss: 0.0716 - val_accuracy: 0.8762 - val_loss: 0.7336 - learning_rate: 4.7619e-05\n\nEpoch 13: LearningRateScheduler setting learning rate to 4.761904761904762e-05.\nEpoch 13/100\n\u001b[1m237/237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 332ms/step - accuracy: 0.9517 - loss: 0.1721 - val_accuracy: 0.8913 - val_loss: 0.5199 - learning_rate: 4.7619e-05\n\nEpoch 14: LearningRateScheduler setting learning rate to 4.761904761904762e-05.\nEpoch 14/100\n\u001b[1m237/237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 335ms/step - accuracy: 0.9669 - loss: 0.1284 - val_accuracy: 0.9278 - val_loss: 0.2875 - learning_rate: 4.7619e-05\n\nEpoch 15: LearningRateScheduler setting learning rate to 4.761904761904762e-05.\nEpoch 15/100\n\u001b[1m237/237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 330ms/step - accuracy: 0.9910 - loss: 0.0398 - val_accuracy: 0.9056 - val_loss: 0.4825 - learning_rate: 4.7619e-05\n\nEpoch 16: LearningRateScheduler setting learning rate to 4.761904761904762e-05.\nEpoch 16/100\n\u001b[1m237/237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 331ms/step - accuracy: 0.9820 - loss: 0.0630 - val_accuracy: 0.9365 - val_loss: 0.3490 - learning_rate: 4.7619e-05\n\nEpoch 17: LearningRateScheduler setting learning rate to 4.761904761904762e-05.\nEpoch 17/100\n\u001b[1m237/237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 330ms/step - accuracy: 0.9886 - loss: 0.0352 - val_accuracy: 0.9222 - val_loss: 0.5568 - learning_rate: 4.7619e-05\n\nEpoch 18: LearningRateScheduler setting learning rate to 4.761904761904762e-05.\nEpoch 18/100\n\u001b[1m237/237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 330ms/step - accuracy: 0.9746 - loss: 0.1114 - val_accuracy: 0.9111 - val_loss: 0.4323 - learning_rate: 4.7619e-05\n\nEpoch 19: LearningRateScheduler setting learning rate to 4.761904761904762e-05.\nEpoch 19/100\n\u001b[1m237/237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 330ms/step - accuracy: 0.9915 - loss: 0.0365 - val_accuracy: 0.9333 - val_loss: 0.3059 - learning_rate: 4.7619e-05\n\nEpoch 20: LearningRateScheduler setting learning rate to 4.761904761904762e-05.\nEpoch 20/100\n\u001b[1m237/237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 330ms/step - accuracy: 0.9936 - loss: 0.0171 - val_accuracy: 0.9405 - val_loss: 0.4635 - learning_rate: 4.7619e-05\n\nEpoch 21: LearningRateScheduler setting learning rate to 4.761904761904762e-05.\nEpoch 21/100\n\u001b[1m237/237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 330ms/step - accuracy: 0.9998 - loss: 0.0010 - val_accuracy: 0.9437 - val_loss: 0.4153 - learning_rate: 4.7619e-05\n\nEpoch 22: LearningRateScheduler setting learning rate to 4.761904761904762e-05.\nEpoch 22/100\n\u001b[1m237/237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 330ms/step - accuracy: 0.9824 - loss: 0.0785 - val_accuracy: 0.8913 - val_loss: 0.4794 - learning_rate: 4.7619e-05\n\nEpoch 23: LearningRateScheduler setting learning rate to 4.761904761904762e-05.\nEpoch 23/100\n\u001b[1m237/237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 330ms/step - accuracy: 0.9660 - loss: 0.1006 - val_accuracy: 0.9206 - val_loss: 0.5456 - learning_rate: 4.7619e-05\n\nEpoch 24: LearningRateScheduler setting learning rate to 4.761904761904762e-05.\nEpoch 24/100\n\u001b[1m237/237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 329ms/step - accuracy: 0.9828 - loss: 0.0524 - val_accuracy: 0.9405 - val_loss: 0.4625 - learning_rate: 4.7619e-05\n\nEpoch 25: LearningRateScheduler setting learning rate to 4.761904761904762e-05.\nEpoch 25/100\n\u001b[1m237/237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 329ms/step - accuracy: 0.9964 - loss: 0.0130 - val_accuracy: 0.9294 - val_loss: 0.4741 - learning_rate: 4.7619e-05\n\nEpoch 26: LearningRateScheduler setting learning rate to 4.761904761904762e-05.\nEpoch 26/100\n\u001b[1m237/237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 330ms/step - accuracy: 0.9865 - loss: 0.0482 - val_accuracy: 0.9278 - val_loss: 0.3456 - learning_rate: 4.7619e-05\n\nEpoch 27: LearningRateScheduler setting learning rate to 4.761904761904762e-05.\nEpoch 27/100\n\u001b[1m237/237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 329ms/step - accuracy: 0.9936 - loss: 0.0217 - val_accuracy: 0.9437 - val_loss: 0.3749 - learning_rate: 4.7619e-05\n\nEpoch 28: LearningRateScheduler setting learning rate to 4.761904761904762e-05.\nEpoch 28/100\n\u001b[1m237/237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 329ms/step - accuracy: 0.9985 - loss: 0.0070 - val_accuracy: 0.9214 - val_loss: 0.3071 - learning_rate: 4.7619e-05\n\nEpoch 29: LearningRateScheduler setting learning rate to 4.761904761904762e-05.\nEpoch 29/100\n\u001b[1m237/237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 329ms/step - accuracy: 0.9868 - loss: 0.0460 - val_accuracy: 0.9190 - val_loss: 0.4098 - learning_rate: 4.7619e-05\n\nEpoch 30: LearningRateScheduler setting learning rate to 4.761904761904762e-05.\nEpoch 30/100\n\u001b[1m237/237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 329ms/step - accuracy: 0.9793 - loss: 0.0826 - val_accuracy: 0.9325 - val_loss: 0.4462 - learning_rate: 4.7619e-05\n\nEpoch 31: LearningRateScheduler setting learning rate to 4.761904761904762e-05.\nEpoch 31/100\n\u001b[1m237/237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 331ms/step - accuracy: 0.9946 - loss: 0.0207 - val_accuracy: 0.9183 - val_loss: 0.4554 - learning_rate: 4.7619e-05\n\nEpoch 32: LearningRateScheduler setting learning rate to 4.761904761904762e-05.\nEpoch 32/100\n\u001b[1m237/237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 329ms/step - accuracy: 0.9894 - loss: 0.0410 - val_accuracy: 0.9095 - val_loss: 0.5301 - learning_rate: 4.7619e-05\n\nEpoch 33: LearningRateScheduler setting learning rate to 4.761904761904762e-05.\nEpoch 33/100\n\u001b[1m237/237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 329ms/step - accuracy: 0.9876 - loss: 0.0611 - val_accuracy: 0.9190 - val_loss: 0.5893 - learning_rate: 4.7619e-05\n\nEpoch 34: LearningRateScheduler setting learning rate to 4.761904761904762e-05.\nEpoch 34/100\n\u001b[1m237/237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 329ms/step - accuracy: 0.9794 - loss: 0.0917 - val_accuracy: 0.9246 - val_loss: 0.3325 - learning_rate: 4.7619e-05\n\nEpoch 35: LearningRateScheduler setting learning rate to 4.761904761904762e-05.\nEpoch 35/100\n\u001b[1m237/237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 329ms/step - accuracy: 0.9896 - loss: 0.0350 - val_accuracy: 0.9206 - val_loss: 0.3943 - learning_rate: 4.7619e-05\n\nEpoch 36: LearningRateScheduler setting learning rate to 4.761904761904762e-05.\nEpoch 36/100\n\u001b[1m237/237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 333ms/step - accuracy: 0.9789 - loss: 0.0873 - val_accuracy: 0.9437 - val_loss: 0.2578 - learning_rate: 4.7619e-05\n\nEpoch 37: LearningRateScheduler setting learning rate to 4.761904761904762e-05.\nEpoch 37/100\n\u001b[1m237/237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 329ms/step - accuracy: 0.9965 - loss: 0.0189 - val_accuracy: 0.9365 - val_loss: 0.4560 - learning_rate: 4.7619e-05\n\nEpoch 38: LearningRateScheduler setting learning rate to 4.761904761904762e-05.\nEpoch 38/100\n\u001b[1m237/237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 329ms/step - accuracy: 0.9891 - loss: 0.0476 - val_accuracy: 0.9349 - val_loss: 0.3818 - learning_rate: 4.7619e-05\n\nEpoch 39: LearningRateScheduler setting learning rate to 4.761904761904762e-05.\nEpoch 39/100\n\u001b[1m237/237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 329ms/step - accuracy: 0.9946 - loss: 0.0090 - val_accuracy: 0.9373 - val_loss: 0.4056 - learning_rate: 4.7619e-05\n\nEpoch 40: LearningRateScheduler setting learning rate to 4.761904761904762e-05.\nEpoch 40/100\n\u001b[1m237/237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 329ms/step - accuracy: 0.9999 - loss: 0.0015 - val_accuracy: 0.9484 - val_loss: 0.3848 - learning_rate: 4.7619e-05\n\nEpoch 41: LearningRateScheduler setting learning rate to 4.761904761904762e-05.\nEpoch 41/100\n\u001b[1m237/237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 329ms/step - accuracy: 1.0000 - loss: 1.6281e-04 - val_accuracy: 0.9421 - val_loss: 0.4282 - learning_rate: 4.7619e-05\n\nEpoch 42: LearningRateScheduler setting learning rate to 4.761904761904762e-05.\nEpoch 42/100\n\u001b[1m237/237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 330ms/step - accuracy: 0.9999 - loss: 8.2659e-04 - val_accuracy: 0.9357 - val_loss: 0.4928 - learning_rate: 4.7619e-05\n\nEpoch 43: LearningRateScheduler setting learning rate to 4.761904761904762e-05.\nEpoch 43/100\n\u001b[1m237/237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 329ms/step - accuracy: 0.9808 - loss: 0.0716 - val_accuracy: 0.9214 - val_loss: 0.4867 - learning_rate: 4.7619e-05\n\nEpoch 44: LearningRateScheduler setting learning rate to 4.761904761904762e-05.\nEpoch 44/100\n\u001b[1m237/237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 329ms/step - accuracy: 0.9908 - loss: 0.0382 - val_accuracy: 0.9135 - val_loss: 0.4285 - learning_rate: 4.7619e-05\n\nEpoch 45: LearningRateScheduler setting learning rate to 4.761904761904762e-05.\nEpoch 45/100\n\u001b[1m237/237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 329ms/step - accuracy: 0.9913 - loss: 0.0320 - val_accuracy: 0.9429 - val_loss: 0.3777 - learning_rate: 4.7619e-05\n\nEpoch 46: LearningRateScheduler setting learning rate to 4.761904761904762e-05.\nEpoch 46/100\n\u001b[1m237/237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 329ms/step - accuracy: 0.9996 - loss: 0.0024 - val_accuracy: 0.9429 - val_loss: 0.4290 - learning_rate: 4.7619e-05\n\nEpoch 47: LearningRateScheduler setting learning rate to 4.761904761904762e-05.\nEpoch 47/100\n\u001b[1m237/237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 329ms/step - accuracy: 0.9933 - loss: 0.0259 - val_accuracy: 0.9254 - val_loss: 0.4329 - learning_rate: 4.7619e-05\n\nEpoch 48: LearningRateScheduler setting learning rate to 4.761904761904762e-05.\nEpoch 48/100\n\u001b[1m237/237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 329ms/step - accuracy: 0.9840 - loss: 0.0685 - val_accuracy: 0.9214 - val_loss: 0.5725 - learning_rate: 4.7619e-05\n\nEpoch 49: LearningRateScheduler setting learning rate to 4.761904761904762e-05.\nEpoch 49/100\n\u001b[1m237/237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 329ms/step - accuracy: 0.9880 - loss: 0.0501 - val_accuracy: 0.9294 - val_loss: 0.3954 - learning_rate: 4.7619e-05\n\nEpoch 50: LearningRateScheduler setting learning rate to 4.761904761904762e-05.\nEpoch 50/100\n\u001b[1m237/237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 329ms/step - accuracy: 0.9981 - loss: 0.0096 - val_accuracy: 0.9357 - val_loss: 0.4278 - learning_rate: 4.7619e-05\n\nEpoch 51: LearningRateScheduler setting learning rate to 4.761904761904762e-05.\nEpoch 51/100\n\u001b[1m237/237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 329ms/step - accuracy: 0.9890 - loss: 0.0462 - val_accuracy: 0.9222 - val_loss: 0.5502 - learning_rate: 4.7619e-05\n\nEpoch 52: LearningRateScheduler setting learning rate to 4.761904761904762e-05.\nEpoch 52/100\n\u001b[1m237/237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 329ms/step - accuracy: 0.9884 - loss: 0.0488 - val_accuracy: 0.9302 - val_loss: 0.4277 - learning_rate: 4.7619e-05\n\nEpoch 53: LearningRateScheduler setting learning rate to 4.761904761904762e-05.\nEpoch 53/100\n\u001b[1m237/237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 329ms/step - accuracy: 0.9993 - loss: 0.0025 - val_accuracy: 0.9341 - val_loss: 0.4638 - learning_rate: 4.7619e-05\n\nEpoch 54: LearningRateScheduler setting learning rate to 4.761904761904762e-05.\nEpoch 54/100\n\u001b[1m237/237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 329ms/step - accuracy: 0.9995 - loss: 0.0016 - val_accuracy: 0.9357 - val_loss: 0.5468 - learning_rate: 4.7619e-05\n\nEpoch 55: LearningRateScheduler setting learning rate to 4.761904761904762e-05.\nEpoch 55/100\n\u001b[1m237/237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 329ms/step - accuracy: 0.9945 - loss: 0.0187 - val_accuracy: 0.9159 - val_loss: 0.4218 - learning_rate: 4.7619e-05\n\nEpoch 56: LearningRateScheduler setting learning rate to 4.761904761904762e-05.\nEpoch 56/100\n\u001b[1m237/237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 328ms/step - accuracy: 0.9951 - loss: 0.0201 - val_accuracy: 0.9246 - val_loss: 0.3535 - learning_rate: 4.7619e-05\n\nEpoch 57: LearningRateScheduler setting learning rate to 4.761904761904762e-05.\nEpoch 57/100\n\u001b[1m237/237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 327ms/step - accuracy: 0.9958 - loss: 0.0127 - val_accuracy: 0.9389 - val_loss: 0.3972 - learning_rate: 4.7619e-05\n\nEpoch 58: LearningRateScheduler setting learning rate to 4.761904761904762e-05.\nEpoch 58/100\n\u001b[1m237/237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 329ms/step - accuracy: 1.0000 - loss: 6.2909e-04 - val_accuracy: 0.9381 - val_loss: 0.4392 - learning_rate: 4.7619e-05\n\nEpoch 59: LearningRateScheduler setting learning rate to 4.761904761904762e-05.\nEpoch 59/100\n\u001b[1m237/237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 329ms/step - accuracy: 0.9995 - loss: 6.2790e-04 - val_accuracy: 0.9413 - val_loss: 0.4432 - learning_rate: 4.7619e-05\n\nEpoch 60: LearningRateScheduler setting learning rate to 4.761904761904762e-05.\nEpoch 60/100\n\u001b[1m237/237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 329ms/step - accuracy: 0.9998 - loss: 2.8405e-04 - val_accuracy: 0.9397 - val_loss: 0.4678 - learning_rate: 4.7619e-05\n\nEpoch 61: LearningRateScheduler setting learning rate to 4.761904761904762e-05.\nEpoch 61/100\n\u001b[1m237/237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 328ms/step - accuracy: 0.9997 - loss: 6.5344e-04 - val_accuracy: 0.9421 - val_loss: 0.4929 - learning_rate: 4.7619e-05\n\nEpoch 62: LearningRateScheduler setting learning rate to 4.761904761904762e-05.\nEpoch 62/100\n\u001b[1m237/237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 329ms/step - accuracy: 1.0000 - loss: 3.5579e-04 - val_accuracy: 0.9389 - val_loss: 0.5271 - learning_rate: 4.7619e-05\n\nEpoch 63: LearningRateScheduler setting learning rate to 4.761904761904762e-05.\nEpoch 63/100\n\u001b[1m237/237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 329ms/step - accuracy: 1.0000 - loss: 1.9295e-04 - val_accuracy: 0.9421 - val_loss: 0.5172 - learning_rate: 4.7619e-05\n\nEpoch 64: LearningRateScheduler setting learning rate to 4.761904761904762e-05.\nEpoch 64/100\n\u001b[1m237/237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 329ms/step - accuracy: 1.0000 - loss: 5.1555e-05 - val_accuracy: 0.9413 - val_loss: 0.5337 - learning_rate: 4.7619e-05\n\nEpoch 65: LearningRateScheduler setting learning rate to 4.761904761904762e-05.\nEpoch 65/100\n\u001b[1m237/237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 327ms/step - accuracy: 1.0000 - loss: 8.3664e-05 - val_accuracy: 0.9413 - val_loss: 0.5640 - learning_rate: 4.7619e-05\n\nEpoch 66: LearningRateScheduler setting learning rate to 4.761904761904762e-05.\nEpoch 66/100\n\u001b[1m237/237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 328ms/step - accuracy: 1.0000 - loss: 2.8496e-05 - val_accuracy: 0.9421 - val_loss: 0.5664 - learning_rate: 4.7619e-05\n\nEpoch 67: LearningRateScheduler setting learning rate to 4.761904761904762e-05.\nEpoch 67/100\n\u001b[1m237/237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 329ms/step - accuracy: 1.0000 - loss: 2.4741e-05 - val_accuracy: 0.9405 - val_loss: 0.5575 - learning_rate: 4.7619e-05\n\nEpoch 68: LearningRateScheduler setting learning rate to 4.761904761904762e-05.\nEpoch 68/100\n\u001b[1m237/237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 329ms/step - accuracy: 1.0000 - loss: 2.4948e-05 - val_accuracy: 0.9397 - val_loss: 0.5707 - learning_rate: 4.7619e-05\n\nEpoch 69: LearningRateScheduler setting learning rate to 4.761904761904762e-05.\nEpoch 69/100\n\u001b[1m237/237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 329ms/step - accuracy: 1.0000 - loss: 8.3078e-06 - val_accuracy: 0.9413 - val_loss: 0.5600 - learning_rate: 4.7619e-05\n\nEpoch 70: LearningRateScheduler setting learning rate to 4.761904761904762e-05.\nEpoch 70/100\n\u001b[1m237/237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 329ms/step - accuracy: 1.0000 - loss: 5.0116e-06 - val_accuracy: 0.9421 - val_loss: 0.5759 - learning_rate: 4.7619e-05\n\nEpoch 71: LearningRateScheduler setting learning rate to 4.761904761904762e-05.\nEpoch 71/100\n\u001b[1m237/237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 327ms/step - accuracy: 0.9999 - loss: 0.0011 - val_accuracy: 0.8833 - val_loss: 0.5880 - learning_rate: 4.7619e-05\n\nEpoch 72: LearningRateScheduler setting learning rate to 4.761904761904762e-05.\nEpoch 72/100\n\u001b[1m237/237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 327ms/step - accuracy: 0.9030 - loss: 0.4149 - val_accuracy: 0.9175 - val_loss: 0.3979 - learning_rate: 4.7619e-05\n\nEpoch 73: LearningRateScheduler setting learning rate to 4.761904761904762e-05.\nEpoch 73/100\n\u001b[1m237/237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 329ms/step - accuracy: 0.9898 - loss: 0.0397 - val_accuracy: 0.9024 - val_loss: 0.6632 - learning_rate: 4.7619e-05\n\nEpoch 74: LearningRateScheduler setting learning rate to 4.761904761904762e-05.\nEpoch 74/100\n\u001b[1m237/237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 326ms/step - accuracy: 0.9828 - loss: 0.0646 - val_accuracy: 0.9103 - val_loss: 0.8483 - learning_rate: 4.7619e-05\n\nEpoch 75: LearningRateScheduler setting learning rate to 4.761904761904762e-05.\nEpoch 75/100\n\u001b[1m237/237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 329ms/step - accuracy: 0.9841 - loss: 0.0908 - val_accuracy: 0.9294 - val_loss: 0.4074 - learning_rate: 4.7619e-05\n\nEpoch 76: LearningRateScheduler setting learning rate to 4.761904761904762e-05.\nEpoch 76/100\n\u001b[1m237/237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 329ms/step - accuracy: 0.9951 - loss: 0.0160 - val_accuracy: 0.9135 - val_loss: 0.5277 - learning_rate: 4.7619e-05\n\nEpoch 77: LearningRateScheduler setting learning rate to 4.761904761904762e-05.\nEpoch 77/100\n\u001b[1m237/237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 327ms/step - accuracy: 0.9903 - loss: 0.0349 - val_accuracy: 0.9310 - val_loss: 0.3594 - learning_rate: 4.7619e-05\n\nEpoch 78: LearningRateScheduler setting learning rate to 4.761904761904762e-05.\nEpoch 78/100\n\u001b[1m237/237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 329ms/step - accuracy: 0.9955 - loss: 0.0234 - val_accuracy: 0.9262 - val_loss: 0.4344 - learning_rate: 4.7619e-05\n\nEpoch 79: LearningRateScheduler setting learning rate to 4.761904761904762e-05.\nEpoch 79/100\n\u001b[1m237/237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 329ms/step - accuracy: 0.9987 - loss: 0.0079 - val_accuracy: 0.9333 - val_loss: 0.4503 - learning_rate: 4.7619e-05\n\nEpoch 80: LearningRateScheduler setting learning rate to 4.761904761904762e-05.\nEpoch 80/100\n\u001b[1m237/237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 328ms/step - accuracy: 0.9924 - loss: 0.0188 - val_accuracy: 0.9389 - val_loss: 0.4141 - learning_rate: 4.7619e-05\n\nEpoch 81: LearningRateScheduler setting learning rate to 4.761904761904762e-05.\nEpoch 81/100\n\u001b[1m237/237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 326ms/step - accuracy: 0.9911 - loss: 0.0290 - val_accuracy: 0.9246 - val_loss: 0.3898 - learning_rate: 4.7619e-05\n\nEpoch 82: LearningRateScheduler setting learning rate to 4.761904761904762e-05.\nEpoch 82/100\n\u001b[1m237/237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 329ms/step - accuracy: 0.9944 - loss: 0.0163 - val_accuracy: 0.9429 - val_loss: 0.3925 - learning_rate: 4.7619e-05\n\nEpoch 83: LearningRateScheduler setting learning rate to 4.761904761904762e-05.\nEpoch 83/100\n\u001b[1m237/237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 329ms/step - accuracy: 1.0000 - loss: 3.6719e-04 - val_accuracy: 0.9397 - val_loss: 0.5064 - learning_rate: 4.7619e-05\n\nEpoch 84: LearningRateScheduler setting learning rate to 4.761904761904762e-05.\nEpoch 84/100\n\u001b[1m237/237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 327ms/step - accuracy: 1.0000 - loss: 9.0146e-05 - val_accuracy: 0.9413 - val_loss: 0.5716 - learning_rate: 4.7619e-05\n\nEpoch 85: LearningRateScheduler setting learning rate to 4.761904761904762e-05.\nEpoch 85/100\n\u001b[1m237/237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 326ms/step - accuracy: 1.0000 - loss: 2.8430e-05 - val_accuracy: 0.9413 - val_loss: 0.6175 - learning_rate: 4.7619e-05\n\nEpoch 86: LearningRateScheduler setting learning rate to 4.761904761904762e-05.\nEpoch 86/100\n\u001b[1m237/237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 328ms/step - accuracy: 1.0000 - loss: 3.1129e-05 - val_accuracy: 0.9421 - val_loss: 0.5971 - learning_rate: 4.7619e-05\n\nEpoch 87: LearningRateScheduler setting learning rate to 4.761904761904762e-05.\nEpoch 87/100\n\u001b[1m237/237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 327ms/step - accuracy: 1.0000 - loss: 3.6480e-05 - val_accuracy: 0.9444 - val_loss: 0.5933 - learning_rate: 4.7619e-05\n\nEpoch 88: LearningRateScheduler setting learning rate to 4.761904761904762e-05.\nEpoch 88/100\n\u001b[1m237/237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 329ms/step - accuracy: 1.0000 - loss: 1.0325e-05 - val_accuracy: 0.9444 - val_loss: 0.6232 - learning_rate: 4.7619e-05\n\nEpoch 89: LearningRateScheduler setting learning rate to 4.761904761904762e-05.\nEpoch 89/100\n\u001b[1m237/237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 327ms/step - accuracy: 0.9977 - loss: 0.0124 - val_accuracy: 0.8476 - val_loss: 0.6527 - learning_rate: 4.7619e-05\n\nEpoch 90: LearningRateScheduler setting learning rate to 4.761904761904762e-05.\nEpoch 90/100\n\u001b[1m237/237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 329ms/step - accuracy: 0.9359 - loss: 0.2247 - val_accuracy: 0.9365 - val_loss: 0.3441 - learning_rate: 4.7619e-05\n\nEpoch 91: LearningRateScheduler setting learning rate to 4.761904761904762e-05.\nEpoch 91/100\n\u001b[1m237/237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 328ms/step - accuracy: 0.9762 - loss: 0.1270 - val_accuracy: 0.9254 - val_loss: 0.4203 - learning_rate: 4.7619e-05\n\nEpoch 92: LearningRateScheduler setting learning rate to 4.761904761904762e-05.\nEpoch 92/100\n\u001b[1m237/237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 328ms/step - accuracy: 0.9996 - loss: 0.0055 - val_accuracy: 0.9381 - val_loss: 0.4536 - learning_rate: 4.7619e-05\n\nEpoch 93: LearningRateScheduler setting learning rate to 4.761904761904762e-05.\nEpoch 93/100\n\u001b[1m237/237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 328ms/step - accuracy: 0.9988 - loss: 0.0032 - val_accuracy: 0.9333 - val_loss: 0.4237 - learning_rate: 4.7619e-05\n\nEpoch 94: LearningRateScheduler setting learning rate to 4.761904761904762e-05.\nEpoch 94/100\n\u001b[1m237/237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 326ms/step - accuracy: 0.9981 - loss: 0.0052 - val_accuracy: 0.9413 - val_loss: 0.4694 - learning_rate: 4.7619e-05\n\nEpoch 95: LearningRateScheduler setting learning rate to 4.761904761904762e-05.\nEpoch 95/100\n\u001b[1m237/237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 325ms/step - accuracy: 0.9993 - loss: 0.0034 - val_accuracy: 0.9222 - val_loss: 0.5616 - learning_rate: 4.7619e-05\n\nEpoch 96: LearningRateScheduler setting learning rate to 4.761904761904762e-05.\nEpoch 96/100\n\u001b[1m237/237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 327ms/step - accuracy: 0.9911 - loss: 0.0375 - val_accuracy: 0.9079 - val_loss: 0.4996 - learning_rate: 4.7619e-05\n\nEpoch 97: LearningRateScheduler setting learning rate to 4.761904761904762e-05.\nEpoch 97/100\n\u001b[1m237/237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 329ms/step - accuracy: 0.9845 - loss: 0.0663 - val_accuracy: 0.9262 - val_loss: 0.4588 - learning_rate: 4.7619e-05\n\nEpoch 98: LearningRateScheduler setting learning rate to 4.761904761904762e-05.\nEpoch 98/100\n\u001b[1m237/237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 329ms/step - accuracy: 0.9918 - loss: 0.0289 - val_accuracy: 0.9357 - val_loss: 0.3627 - learning_rate: 4.7619e-05\n\nEpoch 99: LearningRateScheduler setting learning rate to 4.761904761904762e-05.\nEpoch 99/100\n\u001b[1m237/237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 327ms/step - accuracy: 0.9987 - loss: 0.0042 - val_accuracy: 0.9357 - val_loss: 0.4555 - learning_rate: 4.7619e-05\n\nEpoch 100: LearningRateScheduler setting learning rate to 4.761904761904762e-05.\nEpoch 100/100\n\u001b[1m237/237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 329ms/step - accuracy: 1.0000 - loss: 4.6703e-04 - val_accuracy: 0.9365 - val_loss: 0.4693 - learning_rate: 4.7619e-05\n\nEpoch 1: LearningRateScheduler setting learning rate to 4.761904761904762e-05.\nEpoch 1/100\n\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m139s\u001b[0m 791ms/step - accuracy: 1.0000 - loss: 7.2884e-04 - val_accuracy: 0.9373 - val_loss: 0.4726 - learning_rate: 4.7619e-05\n\nEpoch 2: LearningRateScheduler setting learning rate to 4.761904761904762e-05.\nEpoch 2/100\n\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 630ms/step - accuracy: 1.0000 - loss: 1.0479e-04 - val_accuracy: 0.9357 - val_loss: 0.4800 - learning_rate: 4.7619e-05\n\nEpoch 3: LearningRateScheduler setting learning rate to 4.761904761904762e-05.\nEpoch 3/100\n\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 630ms/step - accuracy: 1.0000 - loss: 1.1851e-04 - val_accuracy: 0.9373 - val_loss: 0.4914 - learning_rate: 4.7619e-05\n\nEpoch 4: LearningRateScheduler setting learning rate to 4.761904761904762e-05.\nEpoch 4/100\n\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 633ms/step - accuracy: 1.0000 - loss: 5.9931e-05 - val_accuracy: 0.9373 - val_loss: 0.5037 - learning_rate: 4.7619e-05\n\nEpoch 5: LearningRateScheduler setting learning rate to 4.761904761904762e-05.\nEpoch 5/100\n\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 631ms/step - accuracy: 1.0000 - loss: 4.3108e-05 - val_accuracy: 0.9373 - val_loss: 0.5112 - learning_rate: 4.7619e-05\n\nEpoch 6: LearningRateScheduler setting learning rate to 4.761904761904762e-05.\nEpoch 6/100\n\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 629ms/step - accuracy: 1.0000 - loss: 4.3781e-05 - val_accuracy: 0.9373 - val_loss: 0.5183 - learning_rate: 4.7619e-05\n\nEpoch 7: LearningRateScheduler setting learning rate to 4.761904761904762e-05.\nEpoch 7/100\n\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 631ms/step - accuracy: 1.0000 - loss: 4.7984e-05 - val_accuracy: 0.9373 - val_loss: 0.5259 - learning_rate: 4.7619e-05\n\nEpoch 8: LearningRateScheduler setting learning rate to 4.761904761904762e-05.\nEpoch 8/100\n\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 627ms/step - accuracy: 1.0000 - loss: 4.0470e-05 - val_accuracy: 0.9381 - val_loss: 0.5319 - learning_rate: 4.7619e-05\n\nEpoch 9: LearningRateScheduler setting learning rate to 4.761904761904762e-05.\nEpoch 9/100\n\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 632ms/step - accuracy: 1.0000 - loss: 5.9377e-05 - val_accuracy: 0.9381 - val_loss: 0.5418 - learning_rate: 4.7619e-05\n\nEpoch 10: LearningRateScheduler setting learning rate to 4.761904761904762e-05.\nEpoch 10/100\n\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 628ms/step - accuracy: 1.0000 - loss: 2.0809e-05 - val_accuracy: 0.9381 - val_loss: 0.5485 - learning_rate: 4.7619e-05\n\nEpoch 11: LearningRateScheduler setting learning rate to 4.761904761904762e-05.\nEpoch 11/100\n\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 634ms/step - accuracy: 1.0000 - loss: 2.3693e-05 - val_accuracy: 0.9381 - val_loss: 0.5581 - learning_rate: 4.7619e-05\n\nEpoch 12: LearningRateScheduler setting learning rate to 4.761904761904762e-05.\nEpoch 12/100\n\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 624ms/step - accuracy: 1.0000 - loss: 1.6342e-05 - val_accuracy: 0.9381 - val_loss: 0.5634 - learning_rate: 4.7619e-05\n\nEpoch 13: LearningRateScheduler setting learning rate to 4.761904761904762e-05.\nEpoch 13/100\n\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 634ms/step - accuracy: 1.0000 - loss: 1.0500e-04 - val_accuracy: 0.9373 - val_loss: 0.5730 - learning_rate: 4.7619e-05\n\nEpoch 14: LearningRateScheduler setting learning rate to 4.761904761904762e-05.\nEpoch 14/100\n\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 632ms/step - accuracy: 1.0000 - loss: 1.7898e-05 - val_accuracy: 0.9373 - val_loss: 0.5747 - learning_rate: 4.7619e-05\n\nEpoch 15: LearningRateScheduler setting learning rate to 4.761904761904762e-05.\nEpoch 15/100\n\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 626ms/step - accuracy: 1.0000 - loss: 2.2165e-05 - val_accuracy: 0.9373 - val_loss: 0.5716 - learning_rate: 4.7619e-05\n\nEpoch 16: LearningRateScheduler setting learning rate to 4.761904761904762e-05.\nEpoch 16/100\n\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 624ms/step - accuracy: 1.0000 - loss: 1.6752e-05 - val_accuracy: 0.9373 - val_loss: 0.5782 - learning_rate: 4.7619e-05\n\nEpoch 17: LearningRateScheduler setting learning rate to 4.761904761904762e-05.\nEpoch 17/100\n\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 627ms/step - accuracy: 1.0000 - loss: 8.2142e-06 - val_accuracy: 0.9373 - val_loss: 0.5834 - learning_rate: 4.7619e-05\n\nEpoch 18: LearningRateScheduler setting learning rate to 4.761904761904762e-05.\nEpoch 18/100\n\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 629ms/step - accuracy: 1.0000 - loss: 1.5944e-05 - val_accuracy: 0.9373 - val_loss: 0.5904 - learning_rate: 4.7619e-05\n\nEpoch 19: LearningRateScheduler setting learning rate to 4.761904761904762e-05.\nEpoch 19/100\n\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 627ms/step - accuracy: 1.0000 - loss: 6.4864e-06 - val_accuracy: 0.9373 - val_loss: 0.5962 - learning_rate: 4.7619e-05\n\nEpoch 20: LearningRateScheduler setting learning rate to 4.761904761904762e-05.\nEpoch 20/100\n\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 631ms/step - accuracy: 1.0000 - loss: 1.1179e-05 - val_accuracy: 0.9373 - val_loss: 0.6017 - learning_rate: 4.7619e-05\n\nEpoch 21: LearningRateScheduler setting learning rate to 4.761904761904762e-05.\nEpoch 21/100\n\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 624ms/step - accuracy: 1.0000 - loss: 8.9042e-06 - val_accuracy: 0.9373 - val_loss: 0.6079 - learning_rate: 4.7619e-05\n\nEpoch 22: LearningRateScheduler setting learning rate to 4.761904761904762e-05.\nEpoch 22/100\n\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 629ms/step - accuracy: 1.0000 - loss: 6.4083e-06 - val_accuracy: 0.9373 - val_loss: 0.6124 - learning_rate: 4.7619e-05\n\nEpoch 23: LearningRateScheduler setting learning rate to 4.761904761904762e-05.\nEpoch 23/100\n\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 626ms/step - accuracy: 1.0000 - loss: 5.9998e-06 - val_accuracy: 0.9373 - val_loss: 0.6165 - learning_rate: 4.7619e-05\n\nEpoch 24: LearningRateScheduler setting learning rate to 4.761904761904762e-05.\nEpoch 24/100\n\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 630ms/step - accuracy: 1.0000 - loss: 3.9830e-06 - val_accuracy: 0.9373 - val_loss: 0.6208 - learning_rate: 4.7619e-05\n\nEpoch 25: LearningRateScheduler setting learning rate to 4.761904761904762e-05.\nEpoch 25/100\n\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 626ms/step - accuracy: 1.0000 - loss: 4.9105e-06 - val_accuracy: 0.9373 - val_loss: 0.6269 - learning_rate: 4.7619e-05\n\nEpoch 26: LearningRateScheduler setting learning rate to 4.761904761904762e-05.\nEpoch 26/100\n\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 629ms/step - accuracy: 1.0000 - loss: 4.5670e-06 - val_accuracy: 0.9373 - val_loss: 0.6331 - learning_rate: 4.7619e-05\n\nEpoch 27: LearningRateScheduler setting learning rate to 4.761904761904762e-05.\nEpoch 27/100\n\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 627ms/step - accuracy: 1.0000 - loss: 1.0245e-05 - val_accuracy: 0.9373 - val_loss: 0.6336 - learning_rate: 4.7619e-05\n\nEpoch 28: LearningRateScheduler setting learning rate to 4.761904761904762e-05.\nEpoch 28/100\n\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 630ms/step - accuracy: 1.0000 - loss: 4.0858e-06 - val_accuracy: 0.9373 - val_loss: 0.6397 - learning_rate: 4.7619e-05\n\nEpoch 29: LearningRateScheduler setting learning rate to 4.761904761904762e-05.\nEpoch 29/100\n\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 632ms/step - accuracy: 1.0000 - loss: 3.2371e-06 - val_accuracy: 0.9373 - val_loss: 0.6423 - learning_rate: 4.7619e-05\n\nEpoch 30: LearningRateScheduler setting learning rate to 4.761904761904762e-05.\nEpoch 30/100\n\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 622ms/step - accuracy: 1.0000 - loss: 6.4495e-06 - val_accuracy: 0.9373 - val_loss: 0.6480 - learning_rate: 4.7619e-05\n\nEpoch 31: LearningRateScheduler setting learning rate to 4.761904761904762e-05.\nEpoch 31/100\n\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 623ms/step - accuracy: 1.0000 - loss: 5.2580e-06 - val_accuracy: 0.9365 - val_loss: 0.6547 - learning_rate: 4.7619e-05\n\nEpoch 32: LearningRateScheduler setting learning rate to 4.761904761904762e-05.\nEpoch 32/100\n\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 622ms/step - accuracy: 1.0000 - loss: 2.2213e-06 - val_accuracy: 0.9365 - val_loss: 0.6581 - learning_rate: 4.7619e-05\n\nEpoch 33: LearningRateScheduler setting learning rate to 4.761904761904762e-05.\nEpoch 33/100\n\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 630ms/step - accuracy: 1.0000 - loss: 4.1454e-06 - val_accuracy: 0.9373 - val_loss: 0.6632 - learning_rate: 4.7619e-05\n\nEpoch 34: LearningRateScheduler setting learning rate to 4.761904761904762e-05.\nEpoch 34/100\n\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 630ms/step - accuracy: 1.0000 - loss: 7.0121e-06 - val_accuracy: 0.9389 - val_loss: 0.6879 - learning_rate: 4.7619e-05\n\nEpoch 35: LearningRateScheduler setting learning rate to 4.761904761904762e-05.\nEpoch 35/100\n\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 625ms/step - accuracy: 1.0000 - loss: 1.1794e-06 - val_accuracy: 0.9389 - val_loss: 0.6916 - learning_rate: 4.7619e-05\n\nEpoch 36: LearningRateScheduler setting learning rate to 4.761904761904762e-05.\nEpoch 36/100\n\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 624ms/step - accuracy: 1.0000 - loss: 2.5943e-06 - val_accuracy: 0.9389 - val_loss: 0.6970 - learning_rate: 4.7619e-05\n\nEpoch 37: LearningRateScheduler setting learning rate to 4.761904761904762e-05.\nEpoch 37/100\n\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 624ms/step - accuracy: 1.0000 - loss: 1.0051e-06 - val_accuracy: 0.9389 - val_loss: 0.7000 - learning_rate: 4.7619e-05\n\nEpoch 38: LearningRateScheduler setting learning rate to 4.761904761904762e-05.\nEpoch 38/100\n\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 625ms/step - accuracy: 1.0000 - loss: 3.2616e-06 - val_accuracy: 0.9389 - val_loss: 0.7101 - learning_rate: 4.7619e-05\n\nEpoch 39: LearningRateScheduler setting learning rate to 4.761904761904762e-05.\nEpoch 39/100\n\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 628ms/step - accuracy: 1.0000 - loss: 1.7037e-05 - val_accuracy: 0.9389 - val_loss: 0.7171 - learning_rate: 4.7619e-05\n\nEpoch 40: LearningRateScheduler setting learning rate to 4.761904761904762e-05.\nEpoch 40/100\n\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 624ms/step - accuracy: 1.0000 - loss: 1.2364e-06 - val_accuracy: 0.9389 - val_loss: 0.7202 - learning_rate: 4.7619e-05\n\nEpoch 41: LearningRateScheduler setting learning rate to 4.761904761904762e-05.\nEpoch 41/100\n\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 622ms/step - accuracy: 1.0000 - loss: 5.2787e-06 - val_accuracy: 0.9397 - val_loss: 0.7161 - learning_rate: 4.7619e-05\n\nEpoch 42: LearningRateScheduler setting learning rate to 4.761904761904762e-05.\nEpoch 42/100\n\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 620ms/step - accuracy: 1.0000 - loss: 8.8978e-07 - val_accuracy: 0.9397 - val_loss: 0.7193 - learning_rate: 4.7619e-05\n\nEpoch 43: LearningRateScheduler setting learning rate to 4.761904761904762e-05.\nEpoch 43/100\n\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 622ms/step - accuracy: 1.0000 - loss: 1.3798e-06 - val_accuracy: 0.9397 - val_loss: 0.7233 - learning_rate: 4.7619e-05\n\nEpoch 44: LearningRateScheduler setting learning rate to 4.761904761904762e-05.\nEpoch 44/100\n\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 621ms/step - accuracy: 1.0000 - loss: 9.6603e-07 - val_accuracy: 0.9397 - val_loss: 0.7291 - learning_rate: 4.7619e-05\n\nEpoch 45: LearningRateScheduler setting learning rate to 4.761904761904762e-05.\nEpoch 45/100\n\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 625ms/step - accuracy: 1.0000 - loss: 9.3888e-07 - val_accuracy: 0.9397 - val_loss: 0.7302 - learning_rate: 4.7619e-05\n\nEpoch 46: LearningRateScheduler setting learning rate to 4.761904761904762e-05.\nEpoch 46/100\n\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 626ms/step - accuracy: 1.0000 - loss: 4.4809e-06 - val_accuracy: 0.9381 - val_loss: 0.7348 - learning_rate: 4.7619e-05\n\nEpoch 47: LearningRateScheduler setting learning rate to 4.761904761904762e-05.\nEpoch 47/100\n\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 627ms/step - accuracy: 1.0000 - loss: 1.4613e-06 - val_accuracy: 0.9381 - val_loss: 0.7418 - learning_rate: 4.7619e-05\n\nEpoch 48: LearningRateScheduler setting learning rate to 4.761904761904762e-05.\nEpoch 48/100\n\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 625ms/step - accuracy: 1.0000 - loss: 4.9025e-07 - val_accuracy: 0.9381 - val_loss: 0.7456 - learning_rate: 4.7619e-05\n\nEpoch 49: LearningRateScheduler setting learning rate to 4.761904761904762e-05.\nEpoch 49/100\n\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 625ms/step - accuracy: 1.0000 - loss: 3.1585e-07 - val_accuracy: 0.9381 - val_loss: 0.7502 - learning_rate: 4.7619e-05\n\nEpoch 50: LearningRateScheduler setting learning rate to 4.761904761904762e-05.\nEpoch 50/100\n\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 628ms/step - accuracy: 1.0000 - loss: 5.4864e-07 - val_accuracy: 0.9381 - val_loss: 0.7521 - learning_rate: 4.7619e-05\n\nEpoch 51: LearningRateScheduler setting learning rate to 4.761904761904762e-05.\nEpoch 51/100\n\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 632ms/step - accuracy: 1.0000 - loss: 7.2752e-07 - val_accuracy: 0.9389 - val_loss: 0.7569 - learning_rate: 4.7619e-05\n\nEpoch 52: LearningRateScheduler setting learning rate to 4.761904761904762e-05.\nEpoch 52/100\n\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 627ms/step - accuracy: 1.0000 - loss: 7.0027e-07 - val_accuracy: 0.9389 - val_loss: 0.7667 - learning_rate: 4.7619e-05\n\nEpoch 53: LearningRateScheduler setting learning rate to 4.761904761904762e-05.\nEpoch 53/100\n\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 622ms/step - accuracy: 1.0000 - loss: 4.1662e-07 - val_accuracy: 0.9389 - val_loss: 0.7699 - learning_rate: 4.7619e-05\n\nEpoch 54: LearningRateScheduler setting learning rate to 4.761904761904762e-05.\nEpoch 54/100\n\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 622ms/step - accuracy: 1.0000 - loss: 3.8404e-07 - val_accuracy: 0.9397 - val_loss: 0.7734 - learning_rate: 4.7619e-05\n\nEpoch 55: LearningRateScheduler setting learning rate to 4.761904761904762e-05.\nEpoch 55/100\n\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 625ms/step - accuracy: 1.0000 - loss: 5.7323e-07 - val_accuracy: 0.9397 - val_loss: 0.7811 - learning_rate: 4.7619e-05\n\nEpoch 56: LearningRateScheduler setting learning rate to 4.761904761904762e-05.\nEpoch 56/100\n\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 624ms/step - accuracy: 1.0000 - loss: 2.2986e-07 - val_accuracy: 0.9397 - val_loss: 0.7848 - learning_rate: 4.7619e-05\n\nEpoch 57: LearningRateScheduler setting learning rate to 4.761904761904762e-05.\nEpoch 57/100\n\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 622ms/step - accuracy: 1.0000 - loss: 4.9165e-07 - val_accuracy: 0.9397 - val_loss: 0.7876 - learning_rate: 4.7619e-05\n\nEpoch 58: LearningRateScheduler setting learning rate to 4.761904761904762e-05.\nEpoch 58/100\n\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 621ms/step - accuracy: 1.0000 - loss: 6.0594e-07 - val_accuracy: 0.9397 - val_loss: 0.7917 - learning_rate: 4.7619e-05\n\nEpoch 59: LearningRateScheduler setting learning rate to 4.761904761904762e-05.\nEpoch 59/100\n\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 625ms/step - accuracy: 1.0000 - loss: 3.6510e-07 - val_accuracy: 0.9397 - val_loss: 0.7978 - learning_rate: 4.7619e-05\n\nEpoch 60: LearningRateScheduler setting learning rate to 4.761904761904762e-05.\nEpoch 60/100\n\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 626ms/step - accuracy: 1.0000 - loss: 3.3241e-07 - val_accuracy: 0.9397 - val_loss: 0.8012 - learning_rate: 4.7619e-05\n\nEpoch 61: LearningRateScheduler setting learning rate to 4.761904761904762e-05.\nEpoch 61/100\n\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 627ms/step - accuracy: 1.0000 - loss: 2.7368e-07 - val_accuracy: 0.9397 - val_loss: 0.8046 - learning_rate: 4.7619e-05\n\nEpoch 62: LearningRateScheduler setting learning rate to 4.761904761904762e-05.\nEpoch 62/100\n\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 627ms/step - accuracy: 1.0000 - loss: 3.0648e-07 - val_accuracy: 0.9397 - val_loss: 0.8088 - learning_rate: 4.7619e-05\n\nEpoch 63: LearningRateScheduler setting learning rate to 4.761904761904762e-05.\nEpoch 63/100\n\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 626ms/step - accuracy: 1.0000 - loss: 3.5176e-07 - val_accuracy: 0.9397 - val_loss: 0.8199 - learning_rate: 4.7619e-05\n\nEpoch 64: LearningRateScheduler setting learning rate to 4.761904761904762e-05.\nEpoch 64/100\n\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 625ms/step - accuracy: 1.0000 - loss: 1.8785e-07 - val_accuracy: 0.9397 - val_loss: 0.8301 - learning_rate: 4.7619e-05\n\nEpoch 65: LearningRateScheduler setting learning rate to 4.761904761904762e-05.\nEpoch 65/100\n\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 622ms/step - accuracy: 1.0000 - loss: 1.8144e-06 - val_accuracy: 0.9405 - val_loss: 0.8398 - learning_rate: 4.7619e-05\n\nEpoch 66: LearningRateScheduler setting learning rate to 4.761904761904762e-05.\nEpoch 66/100\n\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 622ms/step - accuracy: 1.0000 - loss: 1.6904e-07 - val_accuracy: 0.9405 - val_loss: 0.8441 - learning_rate: 4.7619e-05\n\nEpoch 67: LearningRateScheduler setting learning rate to 4.761904761904762e-05.\nEpoch 67/100\n\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 624ms/step - accuracy: 1.0000 - loss: 2.0936e-07 - val_accuracy: 0.9405 - val_loss: 0.8489 - learning_rate: 4.7619e-05\n\nEpoch 68: LearningRateScheduler setting learning rate to 4.761904761904762e-05.\nEpoch 68/100\n\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 627ms/step - accuracy: 1.0000 - loss: 1.4350e-07 - val_accuracy: 0.9405 - val_loss: 0.8527 - learning_rate: 4.7619e-05\n\nEpoch 69: LearningRateScheduler setting learning rate to 4.761904761904762e-05.\nEpoch 69/100\n\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 626ms/step - accuracy: 1.0000 - loss: 1.2521e-07 - val_accuracy: 0.9405 - val_loss: 0.8534 - learning_rate: 4.7619e-05\n\nEpoch 70: LearningRateScheduler setting learning rate to 4.761904761904762e-05.\nEpoch 70/100\n\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 621ms/step - accuracy: 1.0000 - loss: 5.1150e-07 - val_accuracy: 0.9405 - val_loss: 0.8073 - learning_rate: 4.7619e-05\n\nEpoch 71: LearningRateScheduler setting learning rate to 4.761904761904762e-05.\nEpoch 71/100\n\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 619ms/step - accuracy: 1.0000 - loss: 1.7099e-06 - val_accuracy: 0.9413 - val_loss: 0.8518 - learning_rate: 4.7619e-05\n\nEpoch 72: LearningRateScheduler setting learning rate to 4.761904761904762e-05.\nEpoch 72/100\n\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 621ms/step - accuracy: 1.0000 - loss: 2.8930e-07 - val_accuracy: 0.9413 - val_loss: 0.8681 - learning_rate: 4.7619e-05\n\nEpoch 73: LearningRateScheduler setting learning rate to 4.761904761904762e-05.\nEpoch 73/100\n\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 621ms/step - accuracy: 1.0000 - loss: 4.5354e-07 - val_accuracy: 0.9421 - val_loss: 0.8800 - learning_rate: 4.7619e-05\n\nEpoch 74: LearningRateScheduler setting learning rate to 4.761904761904762e-05.\nEpoch 74/100\n\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 622ms/step - accuracy: 1.0000 - loss: 5.4382e-08 - val_accuracy: 0.9421 - val_loss: 0.8861 - learning_rate: 4.7619e-05\n\nEpoch 75: LearningRateScheduler setting learning rate to 4.761904761904762e-05.\nEpoch 75/100\n\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 621ms/step - accuracy: 1.0000 - loss: 6.4658e-08 - val_accuracy: 0.9421 - val_loss: 0.8922 - learning_rate: 4.7619e-05\n\nEpoch 76: LearningRateScheduler setting learning rate to 4.761904761904762e-05.\nEpoch 76/100\n\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 620ms/step - accuracy: 1.0000 - loss: 1.2540e-06 - val_accuracy: 0.9405 - val_loss: 0.8989 - learning_rate: 4.7619e-05\n\nEpoch 77: LearningRateScheduler setting learning rate to 4.761904761904762e-05.\nEpoch 77/100\n\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 619ms/step - accuracy: 1.0000 - loss: 1.4452e-07 - val_accuracy: 0.9413 - val_loss: 0.8995 - learning_rate: 4.7619e-05\n\nEpoch 78: LearningRateScheduler setting learning rate to 4.761904761904762e-05.\nEpoch 78/100\n\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 621ms/step - accuracy: 1.0000 - loss: 1.1261e-07 - val_accuracy: 0.9413 - val_loss: 0.9008 - learning_rate: 4.7619e-05\n\nEpoch 79: LearningRateScheduler setting learning rate to 4.761904761904762e-05.\nEpoch 79/100\n\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 621ms/step - accuracy: 1.0000 - loss: 8.7759e-07 - val_accuracy: 0.9413 - val_loss: 0.9040 - learning_rate: 4.7619e-05\n\nEpoch 80: LearningRateScheduler setting learning rate to 4.761904761904762e-05.\nEpoch 80/100\n\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 621ms/step - accuracy: 1.0000 - loss: 2.1266e-07 - val_accuracy: 0.9405 - val_loss: 0.9092 - learning_rate: 4.7619e-05\n\nEpoch 81: LearningRateScheduler setting learning rate to 4.761904761904762e-05.\nEpoch 81/100\n\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 623ms/step - accuracy: 1.0000 - loss: 3.5739e-08 - val_accuracy: 0.9405 - val_loss: 0.9120 - learning_rate: 4.7619e-05\n\nEpoch 82: LearningRateScheduler setting learning rate to 4.761904761904762e-05.\nEpoch 82/100\n\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 623ms/step - accuracy: 1.0000 - loss: 1.3150e-07 - val_accuracy: 0.9405 - val_loss: 0.9188 - learning_rate: 4.7619e-05\n\nEpoch 83: LearningRateScheduler setting learning rate to 4.761904761904762e-05.\nEpoch 83/100\n\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 623ms/step - accuracy: 1.0000 - loss: 1.8103e-07 - val_accuracy: 0.9405 - val_loss: 0.9139 - learning_rate: 4.7619e-05\n\nEpoch 84: LearningRateScheduler setting learning rate to 4.761904761904762e-05.\nEpoch 84/100\n\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 623ms/step - accuracy: 1.0000 - loss: 6.4989e-08 - val_accuracy: 0.9405 - val_loss: 0.9166 - learning_rate: 4.7619e-05\n\nEpoch 85: LearningRateScheduler setting learning rate to 4.761904761904762e-05.\nEpoch 85/100\n\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 624ms/step - accuracy: 1.0000 - loss: 6.5843e-08 - val_accuracy: 0.9405 - val_loss: 0.9255 - learning_rate: 4.7619e-05\n\nEpoch 86: LearningRateScheduler setting learning rate to 4.761904761904762e-05.\nEpoch 86/100\n\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 625ms/step - accuracy: 1.0000 - loss: 8.2620e-08 - val_accuracy: 0.9405 - val_loss: 0.9357 - learning_rate: 4.7619e-05\n\nEpoch 87: LearningRateScheduler setting learning rate to 4.761904761904762e-05.\nEpoch 87/100\n\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 620ms/step - accuracy: 1.0000 - loss: 1.9571e-08 - val_accuracy: 0.9397 - val_loss: 0.9435 - learning_rate: 4.7619e-05\n\nEpoch 88: LearningRateScheduler setting learning rate to 4.761904761904762e-05.\nEpoch 88/100\n\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 617ms/step - accuracy: 1.0000 - loss: 2.0690e-08 - val_accuracy: 0.9397 - val_loss: 0.9449 - learning_rate: 4.7619e-05\n\nEpoch 89: LearningRateScheduler setting learning rate to 4.761904761904762e-05.\nEpoch 89/100\n\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 618ms/step - accuracy: 1.0000 - loss: 2.2568e-08 - val_accuracy: 0.9397 - val_loss: 0.9538 - learning_rate: 4.7619e-05\n\nEpoch 90: LearningRateScheduler setting learning rate to 4.761904761904762e-05.\nEpoch 90/100\n\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 624ms/step - accuracy: 1.0000 - loss: 2.7986e-07 - val_accuracy: 0.9405 - val_loss: 0.9804 - learning_rate: 4.7619e-05\n\nEpoch 91: LearningRateScheduler setting learning rate to 4.761904761904762e-05.\nEpoch 91/100\n\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 619ms/step - accuracy: 1.0000 - loss: 9.1051e-08 - val_accuracy: 0.9405 - val_loss: 0.9782 - learning_rate: 4.7619e-05\n\nEpoch 92: LearningRateScheduler setting learning rate to 4.761904761904762e-05.\nEpoch 92/100\n\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 615ms/step - accuracy: 1.0000 - loss: 9.0886e-09 - val_accuracy: 0.9405 - val_loss: 0.9781 - learning_rate: 4.7619e-05\n\nEpoch 93: LearningRateScheduler setting learning rate to 4.761904761904762e-05.\nEpoch 93/100\n\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 618ms/step - accuracy: 1.0000 - loss: 1.7851e-08 - val_accuracy: 0.9405 - val_loss: 0.9802 - learning_rate: 4.7619e-05\n\nEpoch 94: LearningRateScheduler setting learning rate to 4.761904761904762e-05.\nEpoch 94/100\n\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 622ms/step - accuracy: 1.0000 - loss: 2.7930e-08 - val_accuracy: 0.9405 - val_loss: 0.9788 - learning_rate: 4.7619e-05\n\nEpoch 95: LearningRateScheduler setting learning rate to 4.761904761904762e-05.\nEpoch 95/100\n\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 623ms/step - accuracy: 1.0000 - loss: 1.4881e-08 - val_accuracy: 0.9405 - val_loss: 0.9808 - learning_rate: 4.7619e-05\n\nEpoch 96: LearningRateScheduler setting learning rate to 4.761904761904762e-05.\nEpoch 96/100\n\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 618ms/step - accuracy: 1.0000 - loss: 2.2977e-08 - val_accuracy: 0.9405 - val_loss: 0.9832 - learning_rate: 4.7619e-05\n\nEpoch 97: LearningRateScheduler setting learning rate to 4.761904761904762e-05.\nEpoch 97/100\n\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 617ms/step - accuracy: 1.0000 - loss: 2.8696e-08 - val_accuracy: 0.9405 - val_loss: 0.9877 - learning_rate: 4.7619e-05\n\nEpoch 98: LearningRateScheduler setting learning rate to 4.761904761904762e-05.\nEpoch 98/100\n\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 617ms/step - accuracy: 1.0000 - loss: 2.4997e-08 - val_accuracy: 0.9405 - val_loss: 0.9876 - learning_rate: 4.7619e-05\n\nEpoch 99: LearningRateScheduler setting learning rate to 4.761904761904762e-05.\nEpoch 99/100\n\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 616ms/step - accuracy: 1.0000 - loss: 6.6946e-09 - val_accuracy: 0.9405 - val_loss: 0.9900 - learning_rate: 4.7619e-05\n\nEpoch 100: LearningRateScheduler setting learning rate to 4.761904761904762e-05.\nEpoch 100/100\n\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 616ms/step - accuracy: 1.0000 - loss: 8.4640e-08 - val_accuracy: 0.9413 - val_loss: 0.9933 - learning_rate: 4.7619e-05\n\nEpoch 1: LearningRateScheduler setting learning rate to 4.761904761904762e-05.\nEpoch 1/100\n\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m200s\u001b[0m 2s/step - accuracy: 1.0000 - loss: 4.0824e-07 - val_accuracy: 0.9397 - val_loss: 0.9663 - learning_rate: 4.7619e-05\n\nEpoch 2: LearningRateScheduler setting learning rate to 4.761904761904762e-05.\nEpoch 2/100\n\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 1s/step - accuracy: 0.9949 - loss: 0.0278 - val_accuracy: 0.8778 - val_loss: 0.5831 - learning_rate: 4.7619e-05\n\nEpoch 3: LearningRateScheduler setting learning rate to 4.761904761904762e-05.\nEpoch 3/100\n\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 1s/step - accuracy: 0.9433 - loss: 0.2113 - val_accuracy: 0.9310 - val_loss: 0.2979 - learning_rate: 4.7619e-05\n\nEpoch 4: LearningRateScheduler setting learning rate to 4.761904761904762e-05.\nEpoch 4/100\n\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 1s/step - accuracy: 0.9964 - loss: 0.0131 - val_accuracy: 0.9302 - val_loss: 0.4882 - learning_rate: 4.7619e-05\n\nEpoch 5: LearningRateScheduler setting learning rate to 4.761904761904762e-05.\nEpoch 5/100\n\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 1s/step - accuracy: 0.9970 - loss: 0.0140 - val_accuracy: 0.9111 - val_loss: 0.4690 - learning_rate: 4.7619e-05\n\nEpoch 6: LearningRateScheduler setting learning rate to 4.761904761904762e-05.\nEpoch 6/100\n\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 1s/step - accuracy: 0.9949 - loss: 0.0149 - val_accuracy: 0.9270 - val_loss: 0.6320 - learning_rate: 4.7619e-05\n\nEpoch 7: LearningRateScheduler setting learning rate to 4.761904761904762e-05.\nEpoch 7/100\n\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 1s/step - accuracy: 0.9938 - loss: 0.0354 - val_accuracy: 0.9151 - val_loss: 0.4517 - learning_rate: 4.7619e-05\n\nEpoch 8: LearningRateScheduler setting learning rate to 4.761904761904762e-05.\nEpoch 8/100\n\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 1s/step - accuracy: 0.9944 - loss: 0.0251 - val_accuracy: 0.9302 - val_loss: 0.4562 - learning_rate: 4.7619e-05\n\nEpoch 9: LearningRateScheduler setting learning rate to 4.761904761904762e-05.\nEpoch 9/100\n\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 1s/step - accuracy: 0.9991 - loss: 0.0036 - val_accuracy: 0.9294 - val_loss: 0.4941 - learning_rate: 4.7619e-05\n\nEpoch 10: LearningRateScheduler setting learning rate to 4.761904761904762e-05.\nEpoch 10/100\n\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 2.4887e-04 - val_accuracy: 0.9302 - val_loss: 0.5212 - learning_rate: 4.7619e-05\n\nEpoch 11: LearningRateScheduler setting learning rate to 4.761904761904762e-05.\nEpoch 11/100\n\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 2.7542e-04 - val_accuracy: 0.9310 - val_loss: 0.5437 - learning_rate: 4.7619e-05\n\nEpoch 12: LearningRateScheduler setting learning rate to 4.761904761904762e-05.\nEpoch 12/100\n\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 1.4526e-04 - val_accuracy: 0.9294 - val_loss: 0.5684 - learning_rate: 4.7619e-05\n\nEpoch 13: LearningRateScheduler setting learning rate to 4.761904761904762e-05.\nEpoch 13/100\n\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 9.0804e-05 - val_accuracy: 0.9302 - val_loss: 0.5799 - learning_rate: 4.7619e-05\n\nEpoch 14: LearningRateScheduler setting learning rate to 4.761904761904762e-05.\nEpoch 14/100\n\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 6.3822e-05 - val_accuracy: 0.9302 - val_loss: 0.5981 - learning_rate: 4.7619e-05\n\nEpoch 15: LearningRateScheduler setting learning rate to 4.761904761904762e-05.\nEpoch 15/100\n\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 4.0704e-05 - val_accuracy: 0.9310 - val_loss: 0.6113 - learning_rate: 4.7619e-05\n\nEpoch 16: LearningRateScheduler setting learning rate to 4.761904761904762e-05.\nEpoch 16/100\n\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 5.3231e-05 - val_accuracy: 0.9310 - val_loss: 0.6170 - learning_rate: 4.7619e-05\n\nEpoch 17: LearningRateScheduler setting learning rate to 4.761904761904762e-05.\nEpoch 17/100\n\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 5.9052e-05 - val_accuracy: 0.9302 - val_loss: 0.6268 - learning_rate: 4.7619e-05\n\nEpoch 18: LearningRateScheduler setting learning rate to 4.761904761904762e-05.\nEpoch 18/100\n\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 2.5209e-05 - val_accuracy: 0.9310 - val_loss: 0.6379 - learning_rate: 4.7619e-05\n\nEpoch 19: LearningRateScheduler setting learning rate to 4.761904761904762e-05.\nEpoch 19/100\n\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 6.8572e-05 - val_accuracy: 0.9310 - val_loss: 0.6538 - learning_rate: 4.7619e-05\n\nEpoch 20: LearningRateScheduler setting learning rate to 4.761904761904762e-05.\nEpoch 20/100\n\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 4.1912e-05 - val_accuracy: 0.9310 - val_loss: 0.6711 - learning_rate: 4.7619e-05\n\nEpoch 21: LearningRateScheduler setting learning rate to 4.761904761904762e-05.\nEpoch 21/100\n\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 3.3795e-05 - val_accuracy: 0.9317 - val_loss: 0.6750 - learning_rate: 4.7619e-05\n\nEpoch 22: LearningRateScheduler setting learning rate to 4.761904761904762e-05.\nEpoch 22/100\n\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 1.7602e-05 - val_accuracy: 0.9317 - val_loss: 0.6831 - learning_rate: 4.7619e-05\n\nEpoch 23: LearningRateScheduler setting learning rate to 4.761904761904762e-05.\nEpoch 23/100\n\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 4.1365e-05 - val_accuracy: 0.9294 - val_loss: 0.6917 - learning_rate: 4.7619e-05\n\nEpoch 24: LearningRateScheduler setting learning rate to 4.761904761904762e-05.\nEpoch 24/100\n\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 3.0147e-05 - val_accuracy: 0.9286 - val_loss: 0.6937 - learning_rate: 4.7619e-05\n\nEpoch 25: LearningRateScheduler setting learning rate to 4.761904761904762e-05.\nEpoch 25/100\n\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 9.3525e-06 - val_accuracy: 0.9286 - val_loss: 0.7037 - learning_rate: 4.7619e-05\n\nEpoch 26: LearningRateScheduler setting learning rate to 4.761904761904762e-05.\nEpoch 26/100\n\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 1.5023e-05 - val_accuracy: 0.9278 - val_loss: 0.7154 - learning_rate: 4.7619e-05\n\nEpoch 27: LearningRateScheduler setting learning rate to 4.761904761904762e-05.\nEpoch 27/100\n\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 9.5307e-06 - val_accuracy: 0.9278 - val_loss: 0.7245 - learning_rate: 4.7619e-05\n\nEpoch 28: LearningRateScheduler setting learning rate to 4.761904761904762e-05.\nEpoch 28/100\n\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 8.3772e-06 - val_accuracy: 0.9286 - val_loss: 0.7341 - learning_rate: 4.7619e-05\n\nEpoch 29: LearningRateScheduler setting learning rate to 4.761904761904762e-05.\nEpoch 29/100\n\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 1.1067e-05 - val_accuracy: 0.9278 - val_loss: 0.7404 - learning_rate: 4.7619e-05\n\nEpoch 30: LearningRateScheduler setting learning rate to 4.761904761904762e-05.\nEpoch 30/100\n\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 1.2555e-05 - val_accuracy: 0.9278 - val_loss: 0.7488 - learning_rate: 4.7619e-05\n\nEpoch 31: LearningRateScheduler setting learning rate to 4.761904761904762e-05.\nEpoch 31/100\n\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 8.1964e-06 - val_accuracy: 0.9278 - val_loss: 0.7598 - learning_rate: 4.7619e-05\n\nEpoch 32: LearningRateScheduler setting learning rate to 4.761904761904762e-05.\nEpoch 32/100\n\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 6.7323e-06 - val_accuracy: 0.9278 - val_loss: 0.7642 - learning_rate: 4.7619e-05\n\nEpoch 33: LearningRateScheduler setting learning rate to 4.761904761904762e-05.\nEpoch 33/100\n\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 2.8337e-06 - val_accuracy: 0.9286 - val_loss: 0.7711 - learning_rate: 4.7619e-05\n\nEpoch 34: LearningRateScheduler setting learning rate to 4.761904761904762e-05.\nEpoch 34/100\n\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 6.0631e-06 - val_accuracy: 0.9278 - val_loss: 0.7779 - learning_rate: 4.7619e-05\n\nEpoch 35: LearningRateScheduler setting learning rate to 4.761904761904762e-05.\nEpoch 35/100\n\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 9.2192e-06 - val_accuracy: 0.9286 - val_loss: 0.7834 - learning_rate: 4.7619e-05\n\nEpoch 36: LearningRateScheduler setting learning rate to 4.761904761904762e-05.\nEpoch 36/100\n\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 7.7400e-06 - val_accuracy: 0.9286 - val_loss: 0.7922 - learning_rate: 4.7619e-05\n\nEpoch 37: LearningRateScheduler setting learning rate to 4.761904761904762e-05.\nEpoch 37/100\n\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 7.6842e-06 - val_accuracy: 0.9286 - val_loss: 0.8020 - learning_rate: 4.7619e-05\n\nEpoch 38: LearningRateScheduler setting learning rate to 4.761904761904762e-05.\nEpoch 38/100\n\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 4.5086e-06 - val_accuracy: 0.9294 - val_loss: 0.8075 - learning_rate: 4.7619e-05\n\nEpoch 39: LearningRateScheduler setting learning rate to 4.761904761904762e-05.\nEpoch 39/100\n\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 1.1601e-05 - val_accuracy: 0.9310 - val_loss: 0.8160 - learning_rate: 4.7619e-05\n\nEpoch 40: LearningRateScheduler setting learning rate to 4.761904761904762e-05.\nEpoch 40/100\n\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 4.6465e-06 - val_accuracy: 0.9317 - val_loss: 0.8269 - learning_rate: 4.7619e-05\n\nEpoch 41: LearningRateScheduler setting learning rate to 4.761904761904762e-05.\nEpoch 41/100\n\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 2.0182e-06 - val_accuracy: 0.9317 - val_loss: 0.8303 - learning_rate: 4.7619e-05\n\nEpoch 42: LearningRateScheduler setting learning rate to 4.761904761904762e-05.\nEpoch 42/100\n\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 4.1565e-06 - val_accuracy: 0.9310 - val_loss: 0.8394 - learning_rate: 4.7619e-05\n\nEpoch 43: LearningRateScheduler setting learning rate to 4.761904761904762e-05.\nEpoch 43/100\n\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 1.5653e-06 - val_accuracy: 0.9302 - val_loss: 0.8447 - learning_rate: 4.7619e-05\n\nEpoch 44: LearningRateScheduler setting learning rate to 4.761904761904762e-05.\nEpoch 44/100\n\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 2.0130e-06 - val_accuracy: 0.9310 - val_loss: 0.8572 - learning_rate: 4.7619e-05\n\nEpoch 45: LearningRateScheduler setting learning rate to 4.761904761904762e-05.\nEpoch 45/100\n\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 9.8595e-07 - val_accuracy: 0.9310 - val_loss: 0.8634 - learning_rate: 4.7619e-05\n\nEpoch 46: LearningRateScheduler setting learning rate to 4.761904761904762e-05.\nEpoch 46/100\n\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 1.0834e-06 - val_accuracy: 0.9310 - val_loss: 0.8620 - learning_rate: 4.7619e-05\n\nEpoch 47: LearningRateScheduler setting learning rate to 4.761904761904762e-05.\nEpoch 47/100\n\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 1.8432e-06 - val_accuracy: 0.9302 - val_loss: 0.8618 - learning_rate: 4.7619e-05\n\nEpoch 48: LearningRateScheduler setting learning rate to 4.761904761904762e-05.\nEpoch 48/100\n\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 1.4089e-06 - val_accuracy: 0.9302 - val_loss: 0.8681 - learning_rate: 4.7619e-05\n\nEpoch 49: LearningRateScheduler setting learning rate to 4.761904761904762e-05.\nEpoch 49/100\n\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 7.6001e-07 - val_accuracy: 0.9310 - val_loss: 0.8797 - learning_rate: 4.7619e-05\n\nEpoch 50: LearningRateScheduler setting learning rate to 4.761904761904762e-05.\nEpoch 50/100\n\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 1.8495e-06 - val_accuracy: 0.9310 - val_loss: 0.8877 - learning_rate: 4.7619e-05\n\nEpoch 51: LearningRateScheduler setting learning rate to 4.761904761904762e-05.\nEpoch 51/100\n\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 7.3485e-06 - val_accuracy: 0.9310 - val_loss: 0.8593 - learning_rate: 4.7619e-05\n\nEpoch 52: LearningRateScheduler setting learning rate to 4.761904761904762e-05.\nEpoch 52/100\n\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 2.9145e-06 - val_accuracy: 0.9310 - val_loss: 0.8659 - learning_rate: 4.7619e-05\n\nEpoch 53: LearningRateScheduler setting learning rate to 4.761904761904762e-05.\nEpoch 53/100\n\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 1.3174e-06 - val_accuracy: 0.9310 - val_loss: 0.8733 - learning_rate: 4.7619e-05\n\nEpoch 54: LearningRateScheduler setting learning rate to 4.761904761904762e-05.\nEpoch 54/100\n\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 1.2537e-06 - val_accuracy: 0.9310 - val_loss: 0.8806 - learning_rate: 4.7619e-05\n\nEpoch 55: LearningRateScheduler setting learning rate to 4.761904761904762e-05.\nEpoch 55/100\n\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 1.0369e-06 - val_accuracy: 0.9310 - val_loss: 0.8890 - learning_rate: 4.7619e-05\n\nEpoch 56: LearningRateScheduler setting learning rate to 4.761904761904762e-05.\nEpoch 56/100\n\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 4.6456e-07 - val_accuracy: 0.9310 - val_loss: 0.8905 - learning_rate: 4.7619e-05\n\nEpoch 57: LearningRateScheduler setting learning rate to 4.761904761904762e-05.\nEpoch 57/100\n\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 2.0305e-06 - val_accuracy: 0.9302 - val_loss: 0.8968 - learning_rate: 4.7619e-05\n\nEpoch 58: LearningRateScheduler setting learning rate to 4.761904761904762e-05.\nEpoch 58/100\n\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 4.5067e-07 - val_accuracy: 0.9310 - val_loss: 0.8990 - learning_rate: 4.7619e-05\n\nEpoch 59: LearningRateScheduler setting learning rate to 4.761904761904762e-05.\nEpoch 59/100\n\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 3.7765e-07 - val_accuracy: 0.9310 - val_loss: 0.9038 - learning_rate: 4.7619e-05\n\nEpoch 60: LearningRateScheduler setting learning rate to 4.761904761904762e-05.\nEpoch 60/100\n\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m72s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 6.0912e-07 - val_accuracy: 0.9310 - val_loss: 0.9100 - learning_rate: 4.7619e-05\n\nEpoch 61: LearningRateScheduler setting learning rate to 4.761904761904762e-05.\nEpoch 61/100\n\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 5.6144e-07 - val_accuracy: 0.9310 - val_loss: 0.9171 - learning_rate: 4.7619e-05\n\nEpoch 62: LearningRateScheduler setting learning rate to 4.761904761904762e-05.\nEpoch 62/100\n\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 4.2258e-07 - val_accuracy: 0.9310 - val_loss: 0.9206 - learning_rate: 4.7619e-05\n\nEpoch 63: LearningRateScheduler setting learning rate to 4.761904761904762e-05.\nEpoch 63/100\n\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 5.0731e-06 - val_accuracy: 0.9333 - val_loss: 0.8917 - learning_rate: 4.7619e-05\n\nEpoch 64: LearningRateScheduler setting learning rate to 4.761904761904762e-05.\nEpoch 64/100\n\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 2.9250e-07 - val_accuracy: 0.9333 - val_loss: 0.8965 - learning_rate: 4.7619e-05\n\nEpoch 65: LearningRateScheduler setting learning rate to 4.761904761904762e-05.\nEpoch 65/100\n\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 5.3690e-07 - val_accuracy: 0.9333 - val_loss: 0.9053 - learning_rate: 4.7619e-05\n\nEpoch 66: LearningRateScheduler setting learning rate to 4.761904761904762e-05.\nEpoch 66/100\n\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 5.3356e-07 - val_accuracy: 0.9333 - val_loss: 0.9116 - learning_rate: 4.7619e-05\n\nEpoch 67: LearningRateScheduler setting learning rate to 4.761904761904762e-05.\nEpoch 67/100\n\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 5.8985e-07 - val_accuracy: 0.9333 - val_loss: 0.9232 - learning_rate: 4.7619e-05\n\nEpoch 68: LearningRateScheduler setting learning rate to 4.761904761904762e-05.\nEpoch 68/100\n\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 6.8720e-07 - val_accuracy: 0.9333 - val_loss: 0.9360 - learning_rate: 4.7619e-05\n\nEpoch 69: LearningRateScheduler setting learning rate to 4.761904761904762e-05.\nEpoch 69/100\n\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 4.9688e-07 - val_accuracy: 0.9325 - val_loss: 0.9443 - learning_rate: 4.7619e-05\n\nEpoch 70: LearningRateScheduler setting learning rate to 4.761904761904762e-05.\nEpoch 70/100\n\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 3.1074e-07 - val_accuracy: 0.9325 - val_loss: 0.9490 - learning_rate: 4.7619e-05\n\nEpoch 71: LearningRateScheduler setting learning rate to 4.761904761904762e-05.\nEpoch 71/100\n\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 5.5943e-07 - val_accuracy: 0.9325 - val_loss: 0.9510 - learning_rate: 4.7619e-05\n\nEpoch 72: LearningRateScheduler setting learning rate to 4.761904761904762e-05.\nEpoch 72/100\n\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 7.1905e-07 - val_accuracy: 0.9325 - val_loss: 0.9583 - learning_rate: 4.7619e-05\n\nEpoch 73: LearningRateScheduler setting learning rate to 4.761904761904762e-05.\nEpoch 73/100\n\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 2.4170e-07 - val_accuracy: 0.9325 - val_loss: 0.9609 - learning_rate: 4.7619e-05\n\nEpoch 74: LearningRateScheduler setting learning rate to 4.761904761904762e-05.\nEpoch 74/100\n\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 9.8910e-07 - val_accuracy: 0.9325 - val_loss: 0.9679 - learning_rate: 4.7619e-05\n\nEpoch 75: LearningRateScheduler setting learning rate to 4.761904761904762e-05.\nEpoch 75/100\n\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 4.4186e-07 - val_accuracy: 0.9325 - val_loss: 0.9710 - learning_rate: 4.7619e-05\n\nEpoch 76: LearningRateScheduler setting learning rate to 4.761904761904762e-05.\nEpoch 76/100\n\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 8.1660e-07 - val_accuracy: 0.9325 - val_loss: 0.9788 - learning_rate: 4.7619e-05\n\nEpoch 77: LearningRateScheduler setting learning rate to 4.761904761904762e-05.\nEpoch 77/100\n\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 2.6161e-07 - val_accuracy: 0.9325 - val_loss: 0.9823 - learning_rate: 4.7619e-05\n\nEpoch 78: LearningRateScheduler setting learning rate to 4.761904761904762e-05.\nEpoch 78/100\n\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 9.8321e-07 - val_accuracy: 0.9325 - val_loss: 0.9981 - learning_rate: 4.7619e-05\n\nEpoch 79: LearningRateScheduler setting learning rate to 4.761904761904762e-05.\nEpoch 79/100\n\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 3.1843e-07 - val_accuracy: 0.9333 - val_loss: 1.0024 - learning_rate: 4.7619e-05\n\nEpoch 80: LearningRateScheduler setting learning rate to 4.761904761904762e-05.\nEpoch 80/100\n\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 7.3666e-07 - val_accuracy: 0.9333 - val_loss: 1.0087 - learning_rate: 4.7619e-05\n\nEpoch 81: LearningRateScheduler setting learning rate to 4.761904761904762e-05.\nEpoch 81/100\n\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 2.3169e-07 - val_accuracy: 0.9333 - val_loss: 1.0120 - learning_rate: 4.7619e-05\n\nEpoch 82: LearningRateScheduler setting learning rate to 4.761904761904762e-05.\nEpoch 82/100\n\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 7.2119e-07 - val_accuracy: 0.9333 - val_loss: 1.0262 - learning_rate: 4.7619e-05\n\nEpoch 83: LearningRateScheduler setting learning rate to 4.761904761904762e-05.\nEpoch 83/100\n\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 1.0584e-06 - val_accuracy: 0.9333 - val_loss: 1.0324 - learning_rate: 4.7619e-05\n\nEpoch 84: LearningRateScheduler setting learning rate to 4.761904761904762e-05.\nEpoch 84/100\n\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 2.9079e-07 - val_accuracy: 0.9333 - val_loss: 1.0465 - learning_rate: 4.7619e-05\n\nEpoch 85: LearningRateScheduler setting learning rate to 4.761904761904762e-05.\nEpoch 85/100\n\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 4.1074e-07 - val_accuracy: 0.9325 - val_loss: 1.0540 - learning_rate: 4.7619e-05\n\nEpoch 86: LearningRateScheduler setting learning rate to 4.761904761904762e-05.\nEpoch 86/100\n\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 2.3321e-07 - val_accuracy: 0.9325 - val_loss: 1.0600 - learning_rate: 4.7619e-05\n\nEpoch 87: LearningRateScheduler setting learning rate to 4.761904761904762e-05.\nEpoch 87/100\n\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 1.5208e-07 - val_accuracy: 0.9325 - val_loss: 1.0626 - learning_rate: 4.7619e-05\n\nEpoch 88: LearningRateScheduler setting learning rate to 4.761904761904762e-05.\nEpoch 88/100\n\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 1.9974e-07 - val_accuracy: 0.9325 - val_loss: 1.0685 - learning_rate: 4.7619e-05\n\nEpoch 89: LearningRateScheduler setting learning rate to 4.761904761904762e-05.\nEpoch 89/100\n\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 1.9935e-07 - val_accuracy: 0.9325 - val_loss: 1.0695 - learning_rate: 4.7619e-05\n\nEpoch 90: LearningRateScheduler setting learning rate to 4.761904761904762e-05.\nEpoch 90/100\n\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 3.8395e-07 - val_accuracy: 0.9325 - val_loss: 1.0728 - learning_rate: 4.7619e-05\n\nEpoch 91: LearningRateScheduler setting learning rate to 4.761904761904762e-05.\nEpoch 91/100\n\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 7.5108e-08 - val_accuracy: 0.9325 - val_loss: 1.0736 - learning_rate: 4.7619e-05\n\nEpoch 92: LearningRateScheduler setting learning rate to 4.761904761904762e-05.\nEpoch 92/100\n\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 1.0003e-07 - val_accuracy: 0.9325 - val_loss: 1.0759 - learning_rate: 4.7619e-05\n\nEpoch 93: LearningRateScheduler setting learning rate to 4.761904761904762e-05.\nEpoch 93/100\n\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 7.6985e-08 - val_accuracy: 0.9325 - val_loss: 1.0811 - learning_rate: 4.7619e-05\n\nEpoch 94: LearningRateScheduler setting learning rate to 4.761904761904762e-05.\nEpoch 94/100\n\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 1.0360e-07 - val_accuracy: 0.9325 - val_loss: 1.0855 - learning_rate: 4.7619e-05\n\nEpoch 95: LearningRateScheduler setting learning rate to 4.761904761904762e-05.\nEpoch 95/100\n\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 8.0942e-08 - val_accuracy: 0.9325 - val_loss: 1.0882 - learning_rate: 4.7619e-05\n\nEpoch 96: LearningRateScheduler setting learning rate to 4.761904761904762e-05.\nEpoch 96/100\n\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 1.1074e-06 - val_accuracy: 0.9333 - val_loss: 1.0893 - learning_rate: 4.7619e-05\n\nEpoch 97: LearningRateScheduler setting learning rate to 4.761904761904762e-05.\nEpoch 97/100\n\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 8.4370e-08 - val_accuracy: 0.9325 - val_loss: 1.0947 - learning_rate: 4.7619e-05\n\nEpoch 98: LearningRateScheduler setting learning rate to 4.761904761904762e-05.\nEpoch 98/100\n\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 1.7375e-07 - val_accuracy: 0.9325 - val_loss: 1.1006 - learning_rate: 4.7619e-05\n\nEpoch 99: LearningRateScheduler setting learning rate to 4.761904761904762e-05.\nEpoch 99/100\n\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 3.9166e-07 - val_accuracy: 0.9325 - val_loss: 1.1103 - learning_rate: 4.7619e-05\n\nEpoch 100: LearningRateScheduler setting learning rate to 4.761904761904762e-05.\nEpoch 100/100\n\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 1.2751e-07 - val_accuracy: 0.9325 - val_loss: 1.1176 - learning_rate: 4.7619e-05\n","output_type":"stream"}],"execution_count":5},{"cell_type":"markdown","source":"## Visualizamos o comportamento do modelo","metadata":{}},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n\n# Encontra o batch_size com a melhor acurácia de validação\nbest_batch_size = max(history_dict, key=lambda k: max(history_dict[k].history['val_accuracy']))\n\n# Plota os gráficos apenas para o melhor batch_size\nbest_history = history_dict[best_batch_size]\n\nplt.figure(figsize=(14, 5))\n\n# Gráfico de acurácia\nplt.subplot(1, 2, 1)\nplt.plot(best_history.history['accuracy'], label='Train Accuracy')\nplt.plot(best_history.history['val_accuracy'], label='Validation Accuracy')\nplt.title(f'Acurácia (batch_size={best_batch_size})')\nplt.xlabel('Época')\nplt.ylabel('Acurácia')\nplt.legend()\n\n# Gráfico de perda\nplt.subplot(1, 2, 2)\nplt.plot(best_history.history['loss'], label='Train Loss')\nplt.plot(best_history.history['val_loss'], label='Validation Loss')\nplt.title(f'Perda (batch_size={best_batch_size})')\nplt.xlabel('Época')\nplt.ylabel('Perda')\nplt.legend()\n\nplt.tight_layout()\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-14T11:52:29.152371Z","iopub.execute_input":"2025-02-14T11:52:29.152669Z","iopub.status.idle":"2025-02-14T11:52:29.227000Z","shell.execute_reply.started":"2025-02-14T11:52:29.152639Z","shell.execute_reply":"2025-02-14T11:52:29.225881Z"}},"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-1-bd3bfcac3847>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# Encontra o batch_size com a melhor acurácia de validação\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mbest_batch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'val_accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# Plota os gráficos apenas para o melhor batch_size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'history_dict' is not defined"],"ename":"NameError","evalue":"name 'history_dict' is not defined","output_type":"error"}],"execution_count":1},{"cell_type":"code","source":"# Salva o modelo manualmente (opcional)\nmodel.save('/kaggle/working/phytoplankton_bkp.keras')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-14T19:49:19.198182Z","iopub.execute_input":"2025-02-14T19:49:19.198540Z","iopub.status.idle":"2025-02-14T19:49:20.026347Z","shell.execute_reply.started":"2025-02-14T19:49:19.198516Z","shell.execute_reply":"2025-02-14T19:49:20.025344Z"}},"outputs":[],"execution_count":10},{"cell_type":"markdown","source":"## Avaliamos o melhor modelo com os dados de teste","metadata":{}},{"cell_type":"code","source":"from tensorflow.keras.models import load_model\n\n# Carregue o modelo salvo\n# model = load_model('phytoplankton.keras')\n\n# Avalia o modelo no conjunto de teste\nscore = model.evaluate(X_test_p, Y_test_p)\nprint(f\"Resultados para batch_size = {batch_size}:\")\nprint(f\"Test loss: {score[0]}\")\nprint(f\"Test accuracy: {score[1]}\")\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-14T19:35:12.884953Z","iopub.execute_input":"2025-02-14T19:35:12.885355Z","iopub.status.idle":"2025-02-14T19:35:21.100707Z","shell.execute_reply.started":"2025-02-14T19:35:12.885328Z","shell.execute_reply":"2025-02-14T19:35:21.099797Z"}},"outputs":[{"name":"stdout","text":"\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 148ms/step - accuracy: 0.9331 - loss: 1.1825\nResultados para batch_size = 64:\nTest loss: 1.1463239192962646\nTest accuracy: 0.9309523701667786\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"model.summary()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-14T19:36:16.346614Z","iopub.execute_input":"2025-02-14T19:36:16.346936Z","iopub.status.idle":"2025-02-14T19:36:16.366880Z","shell.execute_reply.started":"2025-02-14T19:36:16.346911Z","shell.execute_reply":"2025-02-14T19:36:16.366096Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"\u001b[1mModel: \"sequential\"\u001b[0m\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n│ vgg16 (\u001b[38;5;33mFunctional\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)                 │      \u001b[38;5;34m14,714,688\u001b[0m │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ flatten (\u001b[38;5;33mFlatten\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ dense (\u001b[38;5;33mDense\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)                 │         \u001b[38;5;34m262,656\u001b[0m │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ dropout (\u001b[38;5;33mDropout\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)                 │         \u001b[38;5;34m131,328\u001b[0m │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m)                  │           \u001b[38;5;34m3,084\u001b[0m │\n└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n│ vgg16 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)                 │      <span style=\"color: #00af00; text-decoration-color: #00af00\">14,714,688</span> │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)                 │         <span style=\"color: #00af00; text-decoration-color: #00af00\">262,656</span> │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)                 │         <span style=\"color: #00af00; text-decoration-color: #00af00\">131,328</span> │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">3,084</span> │\n└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Total params: \u001b[0m\u001b[38;5;34m45,335,270\u001b[0m (172.94 MB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">45,335,270</span> (172.94 MB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m15,111,756\u001b[0m (57.65 MB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">15,111,756</span> (57.65 MB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m30,223,514\u001b[0m (115.29 MB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">30,223,514</span> (115.29 MB)\n</pre>\n"},"metadata":{}}],"execution_count":8},{"cell_type":"code","source":"# Gere as previsões do modelo\ny_pred = model.predict(X_test_p)\n\n# Converta as previsões de probabilidades para classes\ny_pred_classes = np.argmax(y_pred, axis=1)\n\n# Converta os rótulos verdadeiros de one-hot encoding para classes\ny_true = np.argmax(Y_test_p, axis=1)\n\n# Gere o relatório de classificação\nfrom sklearn.metrics import classification_report\nprint(classification_report(y_true, y_pred_classes, target_names=categorias))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-14T19:42:49.134337Z","iopub.execute_input":"2025-02-14T19:42:49.134661Z","iopub.status.idle":"2025-02-14T19:42:57.091666Z","shell.execute_reply.started":"2025-02-14T19:42:49.134640Z","shell.execute_reply":"2025-02-14T19:42:57.090856Z"}},"outputs":[{"name":"stdout","text":"\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 132ms/step\n               precision    recall  f1-score   support\n\n     nontoxic       0.95      0.99      0.97       932\n    Noctiluca       0.94      1.00      0.97        34\n     Anabaena       0.93      0.68      0.78        40\n Prorocentrum       0.90      0.76      0.83        25\n      Karenia       0.88      0.96      0.92        24\n       Nostoc       0.75      0.62      0.68        29\n    Nodularia       0.76      0.70      0.73        27\n Oscillatoria       0.85      0.71      0.77        24\nAphanizomenon       0.77      0.79      0.78        29\n  Microcystis       0.94      0.83      0.88        35\n  Gymnodinium       0.90      0.53      0.67        34\n  Skeletonema       0.92      0.85      0.88        27\n\n     accuracy                           0.93      1260\n    macro avg       0.87      0.78      0.82      1260\n weighted avg       0.93      0.93      0.93      1260\n\n","output_type":"stream"}],"execution_count":9}]}